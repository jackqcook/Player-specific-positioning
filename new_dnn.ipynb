{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/bravespositioning/braves_23_sim.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "features = [ 'responsible_fielder',\n",
    "    'launch_speed', 'launch_angle', \n",
    "    'hit_direction', 'distance', 'landing_x', 'landing_y', 'responsible_fielder_x', 'responsible_fielder_y','responsible_fielder_depth'\n",
    "]\n",
    "target = ['is_out']\n",
    "\n",
    "X = df.drop(columns=['is_out'])\n",
    "y = df['is_out']\n",
    "\n",
    "categorical_features = ['responsible_fielder']\n",
    "numerical_features = ['hit_direction','launch_speed', 'launch_angle', 'distance', \n",
    "                      'landing_x', 'landing_y', 'responsible_fielder_x', 'responsible_fielder_y', 'responsible_fielder_depth']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(df[features])\n",
    "\n",
    "# Combine the encoded features with the target variables\n",
    "data_model = pd.concat([data_encoded, df[target]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (X_train.shape[1],)\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='AdamW', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=32, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plot the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Predict probabilities on the training set\n",
    "y_pred_prob_train = model.predict(X_train)\n",
    "\n",
    "# Train a logistic regression model on these probabilities\n",
    "calibration_model = LogisticRegression()\n",
    "calibration_model.fit(y_pred_prob_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Predict probabilities on the test set using the original model\n",
    "y_pred_prob_test = model.predict(X_test)\n",
    "\n",
    "# Calibrate the predicted probabilities using the logistic regression model\n",
    "y_pred_prob_calibrated = calibration_model.predict_proba(y_pred_prob_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Compute and plot the calibration curve for the calibrated model\n",
    "prob_true_calibrated, prob_pred_calibrated = calibration_curve(y_test, y_pred_prob_calibrated, n_bins=10, strategy='uniform')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred_calibrated, prob_true_calibrated, marker='o', label='Calibrated Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot for Calibrated Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score = brier_score_loss(y_test, y_pred_prob_calibrated)\n",
    "print(f\"Brier Score: {brier_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Predict probabilities on the training set\n",
    "y_pred_prob_train = model.predict(X_train).flatten()  # Use predict to get probabilities\n",
    "\n",
    "# Train a logistic regression model on these probabilities\n",
    "calibration_model = LogisticRegression()\n",
    "calibration_model.fit(y_pred_prob_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Predict probabilities on the test set using the original model\n",
    "y_pred_prob_test = model.predict(X_test).flatten()  # Use predict to get probabilities\n",
    "\n",
    "# Calibrate the predicted probabilities using the logistic regression model\n",
    "y_pred_prob_calibrated = calibration_model.predict_proba(y_pred_prob_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Compute and plot the calibration curve for the calibrated model\n",
    "prob_true_calibrated, prob_pred_calibrated = calibration_curve(y_test, y_pred_prob_calibrated, n_bins=10, strategy='uniform')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred_calibrated, prob_true_calibrated, marker='o', label='Calibrated Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot for Calibrated Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making feature engineering changes to hopefully improve the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_distance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msqrt((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponsible_fielder_x\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfielder_landing_x\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponsible_fielder_y\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfielder_landing_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Display the DataFrame with the new column\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "df['relative_distance'] = np.sqrt((df['responsible_fielder_x'] - df['fielder_landing_x'])**2 + (df['responsible_fielder_y'] - df['fielder_landing_y'])**2)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "df.head()\n",
    "df['relative_distance'] = np.sqrt((df['responsible_fielder_x'] - df['fielder_landing_x'])**2 + (df['responsible_fielder_y'] - df['fielder_landing_y'])**2)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Maps \n",
    "import seaborn as sns\n",
    "outs_data = df[df['is_out'] == 1]\n",
    "\n",
    "# List of positions to create heatmaps for\n",
    "positions = outs_data['responsible_fielder'].unique()\n",
    "\n",
    "# Create heatmaps for each position\n",
    "for position in positions:\n",
    "    position_data = outs_data[outs_data['responsible_fielder'] == position]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    heatmap = sns.kdeplot(\n",
    "        x=position_data['responsible_fielder_x'],\n",
    "        y=position_data['responsible_fielder_y'],\n",
    "        cmap='coolwarm',\n",
    "        fill=True,\n",
    "        thresh=0,\n",
    "        levels=100\n",
    "    )\n",
    "    plt.title(f'Heatmap of Where Responsible Fielders Are Making Outs (Position {position})')\n",
    "    plt.xlabel('Responsible Fielder X Coordinate')\n",
    "    plt.ylabel('Responsible Fielder Y Coordinate')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
