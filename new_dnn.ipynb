{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/bravespositioning/braves_23_sim.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "features = [ 'responsible_fielder',\n",
    "    'launch_speed', 'launch_angle', \n",
    "    'hit_direction', 'distance', 'landing_x', 'landing_y', 'responsible_fielder_x', 'responsible_fielder_y','responsible_fielder_depth'\n",
    "]\n",
    "target = ['is_out']\n",
    "\n",
    "X = df.drop(columns=['is_out'])\n",
    "y = df['is_out']\n",
    "\n",
    "categorical_features = ['responsible_fielder']\n",
    "numerical_features = ['hit_direction','launch_speed', 'launch_angle', 'distance', \n",
    "                      'landing_x', 'landing_y', 'responsible_fielder_x', 'responsible_fielder_y', 'responsible_fielder_depth']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(df[features])\n",
    "\n",
    "# Combine the encoded features with the target variables\n",
    "data_model = pd.concat([data_encoded, df[target]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (X_train.shape[1],)\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='AdamW', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=32, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plot the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Predict probabilities on the training set\n",
    "y_pred_prob_train = model.predict(X_train)\n",
    "\n",
    "# Train a logistic regression model on these probabilities\n",
    "calibration_model = LogisticRegression()\n",
    "calibration_model.fit(y_pred_prob_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Predict probabilities on the test set using the original model\n",
    "y_pred_prob_test = model.predict(X_test)\n",
    "\n",
    "# Calibrate the predicted probabilities using the logistic regression model\n",
    "y_pred_prob_calibrated = calibration_model.predict_proba(y_pred_prob_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Compute and plot the calibration curve for the calibrated model\n",
    "prob_true_calibrated, prob_pred_calibrated = calibration_curve(y_test, y_pred_prob_calibrated, n_bins=10, strategy='uniform')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred_calibrated, prob_true_calibrated, marker='o', label='Calibrated Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot for Calibrated Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score = brier_score_loss(y_test, y_pred_prob_calibrated)\n",
    "print(f\"Brier Score: {brier_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
