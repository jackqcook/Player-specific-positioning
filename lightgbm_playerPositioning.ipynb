{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "features = [\n",
    "    'player_name', 'bat_handR', 'launch_speed', 'launch_angle', \n",
    "    'hit_direction', 'distance', 'landing_x', 'landing_y'\n",
    "]\n",
    "target = ['is_out']\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data_encoded = pd.get_dummies(df[features])\n",
    "\n",
    "# Combining the encoded features with the target\n",
    "data_model = pd.concat([data_encoded, df[target]], axis=1)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data_model.drop(columns=target)\n",
    "y = data_model[target]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Creating the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)\n",
    "\n",
    "# Defining the parameters for the LightGBM model\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Training the model\n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = bst.predict(X_test_scaled, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('braves_23_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "features = [\n",
    "    'player_name', 'bat_handR', 'launch_speed', 'launch_angle', \n",
    "    'hit_direction', 'distance', 'landing_x', 'landing_y'\n",
    "]\n",
    "target = ['is_out']\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data_encoded = pd.get_dummies(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1418, 38) (355, 38) (1418, 1) (355, 1)\n"
     ]
    }
   ],
   "source": [
    "data_model = pd.concat([data_encoded, df[target]], axis=1)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data_model.drop(columns=target)\n",
    "y = data_model[target]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m num_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 17\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Predicting on the test set\u001b[39;00m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled, num_iteration\u001b[38;5;241m=\u001b[39mbst\u001b[38;5;241m.\u001b[39mbest_iteration)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Creating the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)\n",
    "\n",
    "# Defining the parameters for the LightGBM model\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Training the model\n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = bst.predict(X_test_scaled, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1418, 38) (355, 38) (1418, 1) (355, 1)\n",
      "[LightGBM] [Info] Number of positive: 902, number of negative: 516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1457\n",
      "[LightGBM] [Info] Number of data points in the train set: 1418, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.636107 -> initscore=0.558508\n",
      "[LightGBM] [Info] Start training from score 0.558508\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_error: 0.157746\n",
      "Accuracy: 0.8422535211267606\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74       119\n",
      "           1       0.84      0.94      0.89       236\n",
      "\n",
      "    accuracy                           0.84       355\n",
      "   macro avg       0.84      0.80      0.81       355\n",
      "weighted avg       0.84      0.84      0.84       355\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78  41]\n",
      " [ 15 221]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "features = [\n",
    "    'player_name', 'bat_handR', 'launch_speed', 'launch_angle', \n",
    "    'hit_direction', 'distance', 'landing_x', 'landing_y'\n",
    "]\n",
    "target = ['is_out']\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data_encoded = pd.get_dummies(df[features])\n",
    "\n",
    "# Combining the encoded features with the target\n",
    "data_model = pd.concat([data_encoded, df[target]], axis=1)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data_model.drop(columns=target)\n",
    "y = data_model[target]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Creating the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)\n",
    "\n",
    "# Defining the parameters for the LightGBM model\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Training the model with a callback for early stopping\n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data], \n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = bst.predict(X_test_scaled, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_binary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
