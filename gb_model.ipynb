{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/bravespositioning/braves_23_sim.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUND BALL MODEL\n",
    "gb_df = df[(df['is_gb'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Embedding, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Simplified feature set with added 'hit_direction' and positional features\n",
    "features_simplified = [\n",
    "    'responsible_fielder', 'hit_direction',\n",
    "    'launch_speed', 'launch_angle',\n",
    "    'responsible_fielder_x', 'responsible_fielder_y', 'responsible_fielder_angle'\n",
    "]\n",
    "target = 'is_out'\n",
    "# Separate features and target\n",
    "X_simplified = gb_df[features_simplified].copy()\n",
    "y = gb_df[target]\n",
    "\n",
    "# Encode the categorical feature 'responsible_fielder'\n",
    "label_encoder = LabelEncoder()\n",
    "X_simplified['responsible_fielder'] = label_encoder.fit_transform(X_simplified['responsible_fielder'])\n",
    "\n",
    "# Define numeric features in the simplified set\n",
    "numeric_features_simplified = [\n",
    "    'hit_direction',\n",
    "    'launch_speed', 'launch_angle',\n",
    "    'responsible_fielder_x', 'responsible_fielder_y', 'responsible_fielder_angle'\n",
    "]\n",
    "\n",
    "# Preprocessing pipeline for the simplified numeric data\n",
    "numeric_transformer_simplified = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_simplified = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_simplified, numeric_features_simplified)\n",
    "    ])\n",
    "\n",
    "# Split the data with the simplified features\n",
    "X_train_simplified, X_test_simplified, y_train, y_test = train_test_split(X_simplified, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to numeric features\n",
    "X_train_processed_simplified = preprocessor_simplified.fit_transform(X_train_simplified)\n",
    "X_test_processed_simplified = preprocessor_simplified.transform(X_test_simplified)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define input layers for numeric and categorical features\n",
    "numeric_input = Input(shape=(X_train_processed_simplified.shape[1],), name='numeric_input')\n",
    "embedded_fielder = Embedding(input_dim=len(label_encoder.classes_), output_dim=5, input_length=1)(X_train_simplified['responsible_fielder'])\n",
    "embedded_fielder = Flatten()(embedded_fielder)\n",
    "\n",
    "# Concatenate numeric and embedded features\n",
    "concatenated = concatenate([numeric_input, embedded_fielder])\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_processed_simplified, y_train, epochs=110, batch_size=44, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_processed_simplified, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plotting the training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
