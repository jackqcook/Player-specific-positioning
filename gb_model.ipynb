{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/bravespositioning/braves_23_sim.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUND BALL MODEL\n",
    "gb_df = df[(df['is_gb'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Embedding, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Simplified feature set with added 'hit_direction' and positional features\n",
    "features_simplified = [\n",
    "    'responsible_fielder',\n",
    "    'launch_speed',\n",
    "    'responsible_fielder_angle_diff', 'responsible_fielder_depth',\n",
    "]\n",
    "target = 'is_out'\n",
    "# Separate features and target\n",
    "X_simplified = gb_df[features_simplified].copy()\n",
    "y = gb_df[target]\n",
    "\n",
    "# Encode the categorical feature 'responsible_fielder'\n",
    "label_encoder = LabelEncoder()\n",
    "X_simplified['responsible_fielder'] = label_encoder.fit_transform(X_simplified['responsible_fielder'])\n",
    "\n",
    "# Define numeric features in the simplified set\n",
    "numeric_features_simplified = [\n",
    "    'launch_speed', \n",
    "    'responsible_fielder_angle_diff', 'responsible_fielder_depth',\n",
    "]\n",
    "\n",
    "# Preprocessing pipeline for the simplified numeric data\n",
    "numeric_transformer_simplified = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_simplified = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_simplified, numeric_features_simplified)\n",
    "    ])\n",
    "\n",
    "# Split the data with the simplified features\n",
    "X_train_simplified, X_test_simplified, y_train, y_test = train_test_split(X_simplified, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to numeric features\n",
    "X_train_processed_simplified = preprocessor_simplified.fit_transform(X_train_simplified)\n",
    "X_test_processed_simplified = preprocessor_simplified.transform(X_test_simplified)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define input layers for numeric and categorical features\n",
    "numeric_input = Input(shape=(X_train_processed_simplified.shape[1],), name='numeric_input')\n",
    "embedded_fielder = Embedding(input_dim=len(label_encoder.classes_), output_dim=5, input_length=1)(X_train_simplified['responsible_fielder'])\n",
    "embedded_fielder = Flatten()(embedded_fielder)\n",
    "\n",
    "# Concatenate numeric and embedded features\n",
    "concatenated = concatenate([numeric_input, embedded_fielder])\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_processed_simplified, y_train, epochs=110, batch_size=44, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_processed_simplified, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plotting the training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_prob = model.predict(X_test_processed_simplified)\n",
    "\n",
    "# Since the output is a probability, ensure it's 1-dimensional\n",
    "y_prob = y_prob.flatten()\n",
    "\n",
    "# Calculate the calibration curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "\n",
    "# Plotting the calibration plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model Calibration\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect Calibration\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"Fraction of Positives\")\n",
    "plt.title(\"Calibration Plot\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This got really confusing with the model up above, so I decided to just redo all the preprocessing and then use our model for predictions \n",
    "X_all_num = preprocessor.fit_transform(X_simplified[numeric_features])\n",
    "predictions = model.predict([X_all_num, X_simplified['responsible_fielder']]).flatten()\n",
    "gb_df['predicted_out_probability'] = predictions\n",
    "gb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFIELD PLOT \n",
    "lauch_speed = 85\n",
    "#YOU CHOOSE FIELDER X and Y and responsible rielder\n",
    "fielder = 8 #CFer\n",
    "x,y = np.meshgrid(np.linspace(fielder_x-120,fielder_x + 120,1000), np.linspace(fielder_y - 120,fielder_y + 120,1000))\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "hit_direction_angle = np.arctan2(x,y)\n",
    "new_df = pd.DataFrame({'responsible_fielder': np.ones(x.shape[0]) * fielder,\n",
    "                        'hit_direction': hit_direction_angle,\n",
    "                      'landing_x': x, 'landing_y': y,\n",
    "                       'responsible_fielder_x': np.ones(x.shape[0]) * fielder_x,\n",
    "                      'responsible_fielder_y': np.ones(x.shape[0]) * fielder_y})\n",
    "new_df.responsible_fielder = new_df.responsible_fielder.astype(int)\n",
    "#TODO: run new_df through model and get out prob columns\n",
    "X = new_df[features].copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "# Encode the categorical feature `responsible_fielder`\n",
    "#label_encoder = LabelEncoder()\n",
    "X['responsible_fielder'] = label_encoder.transform(X['responsible_fielder'])\n",
    "\n",
    "# Define numeric features\n",
    "# numeric_features = [\n",
    "#     'hit_direction', 'hangtime', 'landing_x', 'landing_y',\n",
    "#     'responsible_fielder_x', 'responsible_fielder_y'\n",
    "# ]\n",
    "# Create a preprocessing pipeline for numeric data\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features)\n",
    "#     ])\n",
    "\n",
    "X_all_num = preprocessor.transform(X[numeric_features])\n",
    "new_df['outprob'] = model.predict([X_all_num, new_df['responsible_fielder']]).flatten()\n",
    "outprob = new_df.outprob.values\n",
    "outprob = outprob.reshape((1000,1000))\n",
    "x = x.reshape((1000,1000))\n",
    "y = y.reshape((1000,1000))\n",
    "plt.pcolormesh(x,y,outprob, cmap = 'coolwarm')\n",
    "plt.colorbar(label = 'out probability')\n",
    "plt.xlabel('landing x')\n",
    "plt.ylabel('landing y')\n",
    "plt.plot([fielder_x], [fielder_y], 'ko')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
